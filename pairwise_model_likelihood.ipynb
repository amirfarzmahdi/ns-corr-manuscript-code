{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure02: measure likelihood for shared and independent covariance matrix\n",
    "# author: Amir Farzmahdi\n",
    "# last update: May 29th, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required packages\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed for NumPy and Python's random module\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "n_loc = 81\n",
    "n_theta = 9\n",
    "ndim = 10000  # number of test images\n",
    "\n",
    "nfilt = 36\n",
    "ncs_s = 36\n",
    "ncs_i = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_test_res.csv', \"rb\") as fp:\n",
    "    train_test_res = pickle.load(fp)  \n",
    "\n",
    "train_cov_mat = train_test_res['train_cov_mat']\n",
    "test_filter_sz_res_conds = train_test_res['test_filter_sz_res_conds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected image index\n",
    "img_idx = np.arange(0,ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select response of large images to measure the likelihood\n",
    "test_filter_sz_res = np.squeeze(test_filter_sz_res_conds[1,:,img_idx,:])\n",
    "print('shape of test data (image x pair x filter):',test_filter_sz_res.shape)\n",
    "n_timgs = test_filter_sz_res.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geometry mean function\n",
    "def geo_mean_overflow(iterable):\n",
    "    return np.exp(np.log(iterable).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a mask for cov matrix of independent case\n",
    "mask = np.zeros((nfilt,nfilt))\n",
    "mask[:int(nfilt/2),:int(nfilt/2)] = 1\n",
    "mask[int(nfilt/2):,int(nfilt/2):] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mask\n",
    "fig = plt.figure(1,figsize=(3.5,3))\n",
    "cax = sns.heatmap(mask)\n",
    "cbar = cax.collections[0].colorbar\n",
    "\n",
    "# # set axes ticks\n",
    "xticks = [0,18,36]\n",
    "xticks_offest = 0\n",
    "xticks = [x + xticks_offest for x in xticks]\n",
    "\n",
    "yticks = [0,18,36]\n",
    "yticks_offest = 0\n",
    "yticks = [x + yticks_offest for x in yticks]\n",
    "\n",
    "xtick_labels = np.char.mod('%d', xticks)\n",
    "ytick_labels = np.char.mod('%d', yticks)\n",
    "\n",
    "plt.xticks(xticks,labels=xtick_labels)\n",
    "plt.yticks(yticks,labels=ytick_labels)\n",
    "plt.tick_params(labelsize=8, width=1, length=0.5,\n",
    "                direction='out',which='major',\n",
    "                right=False,top=False,bottom=True,left=True)\n",
    "# set labels\n",
    "plt.xlabel('filter index')\n",
    "plt.ylabel('filter index')\n",
    "\n",
    "# set colorbar parameters\n",
    "cbar.set_ticks([0, 0.5, 1])\n",
    "cbar.set_ticklabels(['0', '0.5', '1'])\n",
    "cbar.ax.tick_params(labelsize=8, width=1, length=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize arrays to store likelihoods, based on Coen-Cagli et. al (2009)\n",
    "p_shared_locs_imgs = np.zeros((n_loc, n_theta))\n",
    "p_indp_locs_imgs = np.zeros((n_loc, n_theta))\n",
    "p_diff = np.zeros((n_loc, n_theta))\n",
    "\n",
    "# loop over locations and orientations\n",
    "for k in range(n_loc):\n",
    "    for j in range(n_theta):\n",
    "        idx = np.linspace((j * nfilt), ((j + 1) * nfilt - 1), nfilt).astype(int)\n",
    "        \n",
    "        # shared case\n",
    "        cov_mat_shared = train_cov_mat[k, j, :, :]\n",
    "        inv_cov_mat_shared = np.linalg.inv(cov_mat_shared)\n",
    "        det_inv_cov_mat_shared = np.linalg.det(inv_cov_mat_shared)\n",
    "        \n",
    "        # independent case\n",
    "        cov_mat_indp = cov_mat_shared * mask\n",
    "        inv_cov_mat_indp = np.linalg.inv(cov_mat_indp)\n",
    "        det_inv_cov_mat_indp = np.linalg.det(inv_cov_mat_indp)\n",
    "        \n",
    "        p_shared = []\n",
    "        p_indp = []\n",
    "        \n",
    "        # loop over test images\n",
    "        for i in range(n_timgs):\n",
    "            img_res = test_filter_sz_res[i, k, idx]\n",
    "            \n",
    "            # shared case likelihood\n",
    "            lambda_shared = np.sqrt(img_res.T @ inv_cov_mat_shared @ img_res)\n",
    "            p_shared.append((np.power(det_inv_cov_mat_shared, 1/2) / np.power(2*math.pi, ncs_s/2)) *\n",
    "                            (sp.special.kv((1-ncs_s/2), lambda_shared) / np.power(lambda_shared, ncs_s/2-1)))\n",
    "            \n",
    "            # independent case likelihood\n",
    "            lambda_indp = np.sqrt(img_res.T @ inv_cov_mat_indp @ img_res)\n",
    "            p_indp.append((np.power(det_inv_cov_mat_indp, 1/2) / np.power(2*math.pi, ncs_i/2)) *\n",
    "                          (sp.special.kv((1-ncs_i/2), lambda_indp) / np.power(lambda_indp, ncs_i/2-1)))\n",
    "        \n",
    "        # calculate geometric mean of likelihoods\n",
    "        p_shared_locs_imgs[k, j] = np.exp(np.mean(np.log(p_shared))) if p_shared else 0.0\n",
    "        p_indp_locs_imgs[k, j] = np.exp(np.mean(np.log(p_indp))) if p_indp else 0.0\n",
    "        p_diff[k, j] = np.log(p_shared_locs_imgs[k, j]) - np.log(p_indp_locs_imgs[k, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save natural images likelihood of shared versus independent pairs\n",
    "save_file_path = \"p_shared_ind_nat_test_images.csv\"\n",
    "with open(save_file_path, \"wb\") as fp:\n",
    "    pickle.dump({\"p_diff\": p_diff,\n",
    "                 \"p_shared\": p_shared_locs_imgs,\n",
    "                 \"p_indp\": p_indp_locs_imgs}, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psycho_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
